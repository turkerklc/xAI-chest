import os
import time
import json
import torch
import pandas as pd
import numpy as np
from torch import nn, optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MultiLabelBinarizer
from PIL import Image
from tqdm import tqdm

# --- AYARLAR (RTX 5090 Ä°Ã‡Ä°N OPTÄ°MÄ°ZE EDÄ°LDÄ°) ---
CONFIG = {
    'IMG_SIZE': 224,        # ResNet standart giriÅŸi (Daha yÃ¼ksek isterseniz 512 yapÄ±n ama 224 daha stabildir)
    'BATCH_SIZE': 64,       # 5090'Ä±n belleÄŸi yeter, artÄ±rÄ±labilir (128 denenebilir)
    'EPOCHS': 20,           # EÄŸitim sÃ¼resi
    'LEARNING_RATE': 1e-4,  # Hassas Ã¶ÄŸrenme
    'DATA_CSV': 'Data_Entry_2017.csv',
    'IMG_DIR': 'images',    # Resimlerin olduÄŸu klasÃ¶r
    'MODEL_SAVE_PATH': 'chest_xray_model.pth',
    'CLASS_NAMES_SAVE_PATH': 'class_names.json'
}

# --- CÄ°HAZ SEÃ‡Ä°MÄ° ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸš€ Cihaz: {device}")
if torch.cuda.is_available():
    print(f"ğŸ”¥ Ekran KartÄ±: {torch.cuda.get_device_name(0)}")

# --- 1. VERÄ° HAZIRLIÄI (DATA PROCESSING) ---
def load_data():
    print("ğŸ“Š Veri seti okunuyor ve iÅŸleniyor...")
    df = pd.read_csv(CONFIG['DATA_CSV'])
    
    # Gereksiz sÃ¼tunlarÄ± atalÄ±m, sadece Resim AdÄ±, HastalÄ±klar ve Hasta ID kalsÄ±n
    df = df[['Image Index', 'Finding Labels', 'Patient ID']]
    
    # HastalÄ±klarÄ± listeye Ã§evir (Ã–rn: "Infiltration|Pneumonia" -> ["Infiltration", "Pneumonia"])
    df['Finding Labels'] = df['Finding Labels'].apply(lambda x: x.split('|'))
    
    return df

# --- 2. HASTA BAZLI BÃ–LME (PATIENT-LEVEL SPLIT) ---
def split_data(df):
    print("âœ‚ï¸ Veri, hasta bazlÄ± bÃ¶lÃ¼nÃ¼yor (Data Leakage Ã–nlemi)...")
    
    patient_ids = df['Patient ID'].unique()
    train_ids, val_ids = train_test_split(patient_ids, test_size=0.2, random_state=42)
    
    train_df = df[df['Patient ID'].isin(train_ids)].reset_index(drop=True)
    val_df = df[df['Patient ID'].isin(val_ids)].reset_index(drop=True)
    
    print(f"âœ… EÄŸitim Seti: {len(train_df)} gÃ¶rÃ¼ntÃ¼")
    print(f"âœ… DoÄŸrulama Seti: {len(val_df)} gÃ¶rÃ¼ntÃ¼")
    
    return train_df, val_df

# --- 3. DATASET SINIFI ---
class ChestXrayDataset(Dataset):
    def __init__(self, df, img_dir, transform=None, mlb=None):
        self.df = df
        self.img_dir = img_dir
        self.transform = transform
        self.mlb = mlb
        
        # Etiketleri One-Hot Encode yap (0 ve 1'lere Ã§evir)
        self.labels = self.mlb.transform(self.df['Finding Labels'])
        self.image_names = self.df['Image Index'].values

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        img_name = self.image_names[idx]
        img_path = os.path.join(self.img_dir, img_name)
        
        try:
            image = Image.open(img_path).convert("RGB")
        except FileNotFoundError:
            # EÄŸer resim bulunamazsa siyah bir resim dÃ¶ndÃ¼r (kodu patlatma)
            print(f"âš ï¸ UyarÄ±: {img_path} bulunamadÄ±, atlanÄ±yor.")
            image = Image.new('RGB', (CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']))

        if self.transform:
            image = self.transform(image)
        
        label = torch.tensor(self.labels[idx], dtype=torch.float32)
        return image, label

# --- 4. MODEL MÄ°MARÄ°SÄ° ---
def build_model(num_classes):
    print("ğŸ—ï¸ ResNet-50 modeli indiriliyor ve hazÄ±rlanÄ±yor...")
    # Weights parametresi yeni PyTorch sÃ¼rÃ¼mleri iÃ§in gÃ¼ncellendi
    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
    
    # Son katmanÄ± bizim hastalÄ±k sayÄ±mÄ±za gÃ¶re deÄŸiÅŸtir
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, num_classes)
    
    return model.to(device)

# --- 5. EÄÄ°TÄ°M DÃ–NGÃœSÃœ ---
def train_model():
    # 1. Veriyi YÃ¼kle
    full_df = load_data()
    
    # 2. Etiketleyiciyi HazÄ±rla (Binarizer)
    mlb = MultiLabelBinarizer()
    mlb.fit(full_df['Finding Labels'])
    classes = mlb.classes_
    print(f" Tespit Edilecek SÄ±nÄ±flar ({len(classes)}): {classes}")
    
    # SÄ±nÄ±f isimlerini kaydet (Frontend iÃ§in kritik!)
    with open(CONFIG['CLASS_NAMES_SAVE_PATH'], 'w') as f:
        json.dump(list(classes), f)
    print(f" SÄ±nÄ±f listesi kaydedildi: {CONFIG['CLASS_NAMES_SAVE_PATH']}")

    # 3. Veriyi BÃ¶l
    train_df, val_df = split_data(full_df)

    # 4. DÃ¶nÃ¼ÅŸÃ¼mler (Augmentation)
    train_transform = transforms.Compose([
        transforms.Resize((CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE'])),
        transforms.RandomHorizontalFlip(), # Ayna efekti
        transforms.RandomRotation(10),     # Hafif dÃ¶ndÃ¼rme
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # ImageNet standartlarÄ±
    ])

    val_transform = transforms.Compose([
        transforms.Resize((CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE'])),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # 5. DataLoaderlarÄ± OluÅŸtur
    train_dataset = ChestXrayDataset(train_df, CONFIG['IMG_DIR'], train_transform, mlb)
    val_dataset = ChestXrayDataset(val_df, CONFIG['IMG_DIR'], val_transform, mlb)

    # num_workers=8 veya 16 yapabilir Eray (CPU Ã§ekirdeÄŸine gÃ¶re)
    train_loader = DataLoader(train_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=False, num_workers=4, pin_memory=True)

    # 6. Modeli Kur
    model = build_model(len(classes))
    
    # Multi-Label iÃ§in Loss Fonksiyonu: BCEWithLogitsLoss
    criterion = nn.BCEWithLogitsLoss()
    optimizer = optim.Adam(model.parameters(), lr=CONFIG['LEARNING_RATE'])
    
    # Ã–ÄŸrenme hÄ±zÄ±nÄ± zamanla azalt (Scheduler)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)

    best_val_loss = float('inf')

    print("\nğŸ”¥ EÄÄ°TÄ°M BAÅLIYOR... (Kahveni al, bu biraz sÃ¼rebilir)\n")
    
    for epoch in range(CONFIG['EPOCHS']):
        start_time = time.time()
        
        # --- TRAIN ---
        model.train()
        train_loss = 0.0
        
        loop = tqdm(train_loader, desc=f"Epoch {epoch+1}/{CONFIG['EPOCHS']} [Train]")
        for images, labels in loop:
            images, labels = images.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item() * images.size(0)
            loop.set_postfix(loss=loss.item())
            
        train_loss = train_loss / len(train_loader.dataset)

        # --- VALIDATION ---
        model.eval()
        val_loss = 0.0
        
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * images.size(0)
        
        val_loss = val_loss / len(val_loader.dataset)
        
        # Scheduler AdÄ±mÄ±
        scheduler.step(val_loss)

        # SÃ¼re ve Log
        epoch_time = time.time() - start_time
        print(f"Epoch {epoch+1} Bitti | SÃ¼re: {epoch_time:.0f}s | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}")

        # Checkpoint: EÄŸer model geliÅŸtiyse kaydet
        if val_loss < best_val_loss:
            print(f"â­ Validation Loss dÃ¼ÅŸtÃ¼ ({best_val_loss:.4f} -> {val_loss:.4f}). Model kaydediliyor...")
            best_val_loss = val_loss
            torch.save(model.state_dict(), CONFIG['MODEL_SAVE_PATH'])

    print("\nâœ… EÄÄ°TÄ°M TAMAMLANDI!")
    print(f"ğŸ† En iyi model ÅŸuraya kaydedildi: {CONFIG['MODEL_SAVE_PATH']}")

if __name__ == '__main__':
    train_model()